# Determining optimal police patrol deployments: a simulation-based optimisation approach combining Agent-Based Modelling and Genetic Algorithms.


## Project Description

This repository provides complementary code and data for the work undertaken during my PhD.




### Motivations: What problem does it solve? What your model does,

The model was build in a generic manner so as to be applied to any police force. It is made of two components:
- an Agent-Based Model that simulates the dispatching of police patrols throughout a given shift
- a Genetic Algorithm that searches for the optimal number and spatial positioning of police patrols.

- Why you used the technologies you used,

- Some of the challenges you faced and features you hope to implement in the future.


- Demand scenarios, explain

## Structure

The `src` folder contains the model codebase, split into an `ABM` folder -- containing the code for running the ABM on its own -- and a `GA` folder with the code to run the ABM-based (single and multi-objective) optimisation.

The `data` folder is where all the necessary data files need to be placed to run the analysis. Ensure the files are named correctly when you replace them with your own. The required files are:

1. Spatial entities:
- `patrol_beats` folder: contains the shapefiles for the patrol beats (i.e. the smaller spatial unit within which agents are deployed to patrol)
- `precincts` folder: contains the shapefiles for the districts/precincts (i.e. the larger spatial unit within which agents are dispatched to calls)
- `stations.csv` (only needed to be displayed in the ABM animated GIF)
- `G.gpickle`: the networkX graph representing the road network of the police force (see below for details on how it is generated)
- `G_proj.gpickle`: the networkX graph representing the road network of the police force, projected to UTM (see below for details on how it is generated)

2. Historical crimes and CFS incidents:
- `incidents.csv`: a dataset of historical CFS incidents (see below for details of required columns)
- `crimes.csv`: a dataset of historical crimes (see below for details of required columns) 

3. Historical, training and test sets for ABM experiments and GA training (see below for how these are generated):
- `historical_set_scenario1.pkl`
- `historical_set_scenario2.pkl`
- `training_set_scenario1.pkl`
- `training_set_scenario2.pkl`
- `testing_set_scenario1.pkl`
- `testing_set_scenario2.pkl`

The folder `dpd_case_study` contains all the files pertaining to the case study on Detroit Police Department (DPD), Michigan. It contains a `data` folder with the datasets used in the case study, as well as a series of folders containing the code and results for various analyses conducted on the model:
- experiments using the ABM on DPD
- results of the single and multi-objective GAs applied to DPD




## Installation

Key dependencies include (see provided yml file for versions that were used):

For the ABM:
- `osmnx` for downlading the road network of a police force and calculating fastest routes
- `networkX`for manipulating the road network graph generated by osmnx
- `geopandas` for manipulating the spatial dataframes generated by osmnx
- `imageio` for producing a GIF of the ABM
- `multiprocessing` (optional) to use multiple cores and thus speed up the running of the ABM

For the GA:
- `deap`

The `ABM` codebase is composed of the following files:
- `AgentFramework.py`: the attributes and methods for the agent entities
- `ModelFramework.py`: the model entity
- `SchedulerFramework.py`: the model scheduler 
- `IncidentFramework.py`: the attributes and methods for the incident entities
- `GraphFramework.py`: the attributes and methods for the road network (networkX graph and complimentary node and edge data)
- `BeatFramework.py`: the attributes and methods for the patrol beats
- `Env.py`: the initialisation of the model environment composed of the road network, the patrol beats and the incidents for the time period.




## Usage

### Example of DPD case study

#### Running the ABM for DPD

#### Generating historical, training and test sets

In `generating_data_sets.ipynb` we create historical, training and test sets for both demand scenarios. 

A set is a collection of 100 specifically selected time periods from sepearate years to mimic the manner in which police agencies make decisions based on past demand.
- historical set: 100 time periods from 2017
- training set: 100 time periods from 2018
- test set: 100 time periods from 2019

For more details on what these sets are used for, see `generating_data_sets.ipynb`.
Ensure that the 6 generated sets are placed in the `data` folder at the source of the repository.

#### Running the ABM for DPD
An example on how to run the ABM is provided in `dpd_case_study/ABM_running_example/ABM_running_example`.

![alt text](https://github.com/mednche/police-deployment-optimisation/blob/main/dpd_case_study/ABM_running_example/ABM_animation_gif/20_agents/20_steps.gif)

For faster results, it is recommended to harness the power of multiprocessing if your machine has multiple cores (example not provided). 


#### Running the ABM+GA for DPD

Expected time of running the GA on multiprocessing 



### Using a custom police force

To run the ABM for a different police force, it is necessary to first aquire the following files and place them in the `data` folder: 

1. `G.gpickle` and `G_proj.gpickle`: using the jupyter notebook `dpd_case_study/getting_the_road_network`, download the road network for your chosen police force using osmnx and save the graph as `G.pickle` and its projected version as `G_proj.gpickle`. May need to provide a simple jupyter notebook for that.
2. `patrol_beats.shp`: Acquire the patrol beat shapefile and save as `patrol_beats.shp`.
3. Optional: for producing a GIF, the code requires a `precincts.shp` and a `stations.csv`, although these are optional.


## Licence

MIT

