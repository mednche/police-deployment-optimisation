{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate historical, training and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we create a total of 6 sets of time periods as follows:\n",
    "\n",
    "1. Two **historical sets** (for scenario 1 and 2) from the year **2017**. \n",
    "    - historical_set_scenario_1: 100 low demand time periods (weekday 8am-4pm)\n",
    "    - historical_set_scenario_2: 100 high-demand time periods (weekend (midnight-8am)\n",
    "\n",
    "In the multi-objective GA, this is used to select a subset of all historical crimes for these 100 time periods in order to:\n",
    "    - measure the density of historical incidents/crimes on each street (used to calculate deterrence score)\n",
    "    - identify the 5 hottest streets to patrol in each beat as part of the patrol route\n",
    "    - inform the design of configurations targeted towards historically hot beats\n",
    "\n",
    "There is no measure of deterrence needed in the single-objective GA so no need to collect historical incidents/crimes.\n",
    "\n",
    "2. Two **training sets** (for scenario 1 and 2) from the year **2018**: \n",
    "    - training_set_scenario_1: 100 low demand time periods (weekday 8am-4pm)\n",
    "    - training_set_scenario_2: 100 high-demand time periods (weekend (midnight-8am)\n",
    "\n",
    "In the ABM experiments, this is used as a 'historical set' but for the year 2018. The goal is to select a subset of all historical CFS incidents or crimes for these 100 time periods in order to:\n",
    "    - measure the density of historical incidents/crimes on each street (used to calculate deterrence score)\n",
    "    - identify the 5 hottest streets to patrol in each beat as part of the patrol route\n",
    "    - inform the design of configurations targeted towards historically hot beats\n",
    "\n",
    "In the single-objective and multi-objective GAs, this is used to train the GA ($k$ time periods at a time, where $k$ is the RSS value). In other words, at each generation, we evaluate each individual in the population by running $k$ ABMs (for $k$ time periods randomly sampled at each generations).\n",
    "\n",
    "\n",
    "3. Two **test sets** (for scenario 1 and 2) from the year **2019**: \n",
    "    - testing_set_scenario_1: 100 low demand time periods (weekday 8am-4pm)\n",
    "    - testing_set_scenario_2: 100 high-demand time periods (weekend (midnight-8am)\n",
    "\n",
    "In the ABM experiments, this is used to run a simulation for each of these 100 time periods, and present aggregated performance metrics.\n",
    "\n",
    "In the single-objective and multi-objective GAs, this is used to run a final evaluation of the 'best' solutions identifed by the GA on time periods previously unseen during training. This provide a fair and equal evaluation of all the indivuals on the same 100 time periods.\n",
    "\n",
    "\n",
    "NB: by design, all three types of set contain different time periods as they belong to different years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta, time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getYearData(YEAR) :\n",
    "    data = pd.read_csv(\"../data/incidents.csv\")\n",
    "    data.Date_Time = pd.to_datetime(data.Date_Time)\n",
    "    data.Date_Time = data.Date_Time.dt.tz_localize(None)\n",
    "   \n",
    "    data = data[(data['Date_Time'].dt.year == YEAR)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end_shift(date, start_time):\n",
    "    duration_hours = 8\n",
    "    start_time = time(start_time,0)\n",
    "\n",
    "    SHIFT_START_DT = datetime.combine(date, start_time)\n",
    "    SHIFT_END_DT = SHIFT_START_DT + timedelta(hours = duration_hours)\n",
    "    END_TIME = SHIFT_END_DT.time()\n",
    "\n",
    "    return SHIFT_START_DT, SHIFT_END_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSetForScenario(data, scenario_num) :\n",
    "    print('Scenario: {}'.format(scenario_num))\n",
    "    \n",
    "    ## WEEKDAYS\n",
    "    if scenario_num == 1 :\n",
    "        \n",
    "        # Select the weekdays (Monday to Friday)\n",
    "        df_weekdays = data[data.Date_Time.dt.weekday // 5 == 0]\n",
    "        df_weekdays = df_weekdays[(df_weekdays.Date_Time.dt.hour >= 8) & \n",
    "                                        (df_weekdays.Date_Time.dt.hour < 16)]\n",
    "        \n",
    "        dates_uniques_weekdays = df_weekdays['Date_Time'].sort_values().dt.date.unique()\n",
    "        print('There are {} unique dates in dataset'.format(len(dates_uniques_weekdays)))\n",
    "\n",
    "            \n",
    "        ## get all weekday shifts\n",
    "        all_shifts = [get_start_end_shift(date, 8) for date in  dates_uniques_weekdays]\n",
    "\n",
    "    ## WEEKENDS\n",
    "    else :\n",
    "        # Select the weekend days (Saturday and Sunday)\n",
    "        df_weekends = data[data.Date_Time.dt.weekday // 5 == 1]\n",
    "        df_weekends = df_weekends[(df_weekends.Date_Time.dt.hour >= 0) & \n",
    "                                        (df_weekends.Date_Time.dt.hour < 8)]\n",
    "        \n",
    "        dates_uniques_weekends = df_weekends['Date_Time'].sort_values().dt.date.unique()\n",
    "        print('There are {} unique dates in dataset'.format(len(dates_uniques_weekends)))\n",
    "\n",
    "\n",
    "        # get all weekend shifts\n",
    "        all_shifts = [get_start_end_shift(date, 0) for date in  dates_uniques_weekends]\n",
    "\n",
    "\n",
    "   \n",
    "    # select 100 shifts at random\n",
    "    random.seed(222)\n",
    "    set_for_scenario = random.sample(all_shifts, 100)\n",
    "    return set_for_scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set (2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getYearData(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario: 1\n",
      "There are 261 unique dates in dataset\n",
      "Scenario: 2\n",
      "There are 104 unique dates in dataset\n"
     ]
    }
   ],
   "source": [
    "testing_set_scenario1 = getSetForScenario(data, 1)\n",
    "testing_set_scenario2 = getSetForScenario(data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/testing_set_scenario1.pkl', 'wb') as f:\n",
    "    pickle.dump(testing_set_scenario1, f)\n",
    "with open('../data/testing_set_scenario2.pkl', 'wb') as f:\n",
    "    pickle.dump(testing_set_scenario2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set (2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getYearData(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario: 1\n",
      "There are 261 unique dates in dataset\n",
      "Scenario: 2\n",
      "There are 104 unique dates in dataset\n"
     ]
    }
   ],
   "source": [
    "training_set_scenario1 = getSetForScenario(data, 1)\n",
    "training_set_scenario2 = getSetForScenario(data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/training_set_scenario1.pkl', 'wb') as f:\n",
    "    pickle.dump(training_set_scenario1, f)\n",
    "with open('../data/training_set_scenario2.pkl', 'wb') as f:\n",
    "    pickle.dump(training_set_scenario2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical set (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getYearData(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario: 1\n",
      "There are 260 unique dates in dataset\n",
      "Scenario: 2\n",
      "There are 105 unique dates in dataset\n"
     ]
    }
   ],
   "source": [
    "historical_set_scenario1 = getSetForScenario(data, 1)\n",
    "historical_set_scenario2 = getSetForScenario(data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/historical_set_scenario1.pkl', 'wb') as f:\n",
    "    pickle.dump(training_set_scenario1, f)\n",
    "with open('../data/historical_set_scenario2.pkl', 'wb') as f:\n",
    "    pickle.dump(training_set_scenario2, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
